
<!-- saved from url=(0038)https://panxu-ai.github.io/publication -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="color-scheme" content="light dark"></head><body><div class="line-gutter-backdrop"></div><form autocomplete="off"><label class="line-wrap-control">Line wrap<input type="checkbox" aria-label="Line wrap"></label></form><table><tbody><tr><td class="line-number" value="1"></td><td class="line-content"><span class="html-doctype">&lt;!doctype html&gt;</span></td></tr><tr><td class="line-number" value="2"></td><td class="line-content"><span class="html-tag">&lt;html <span class="html-attribute-name">lang</span>="<span class="html-attribute-value">en</span>"&gt;</span></td></tr><tr><td class="line-number" value="3"></td><td class="line-content"><span class="html-tag">&lt;head&gt;</span></td></tr><tr><td class="line-number" value="4"></td><td class="line-content"><span class="html-tag">&lt;meta <span class="html-attribute-name">name</span>="<span class="html-attribute-value">Description</span>" <span class="html-attribute-name">content</span>="<span class="html-attribute-value">I am a final year Ph.D. candidate in the Computer Science Department at the University of California, Los Angeles.</span>"&gt;</span></td></tr><tr><td class="line-number" value="5"></td><td class="line-content"><span class="html-tag">&lt;meta <span class="html-attribute-name">charset</span>="<span class="html-attribute-value">utf-8</span>"&gt;</span></td></tr><tr><td class="line-number" value="6"></td><td class="line-content"><span class="html-tag">&lt;meta <span class="html-attribute-name">name</span>="<span class="html-attribute-value">viewport</span>" <span class="html-attribute-name">content</span>="<span class="html-attribute-value">width=device-width, initial-scale=1</span>"&gt;</span></td></tr><tr><td class="line-number" value="7"></td><td class="line-content"><span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://code.jquery.com/jquery-3.2.1.slim.min.js" rel="noreferrer noopener">https://code.jquery.com/jquery-3.2.1.slim.min.js</a>" <span class="html-attribute-name">integrity</span>="<span class="html-attribute-value">sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN</span>" <span class="html-attribute-name">crossorigin</span>="<span class="html-attribute-value">anonymous</span>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="8"></td><td class="line-content"><span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" rel="noreferrer noopener">https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js</a>" <span class="html-attribute-name">integrity</span>="<span class="html-attribute-value">sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh</span>" <span class="html-attribute-name">crossorigin</span>="<span class="html-attribute-value">anonymous</span>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="9"></td><td class="line-content"><span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" rel="noreferrer noopener">https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css</a>" <span class="html-attribute-name">integrity</span>="<span class="html-attribute-value">sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb</span>" <span class="html-attribute-name">crossorigin</span>="<span class="html-attribute-value">anonymous</span>"&gt;</span></td></tr><tr><td class="line-number" value="10"></td><td class="line-content"><span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" rel="noreferrer noopener">https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js</a>" <span class="html-attribute-name">integrity</span>="<span class="html-attribute-value">sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ</span>" <span class="html-attribute-name">crossorigin</span>="<span class="html-attribute-value">anonymous</span>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="11"></td><td class="line-content"><span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://panxu-ai.github.io/site.css" rel="noreferrer noopener">site.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="12"></td><td class="line-content"><span class="html-tag">&lt;link <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://panxu-ai.github.io/stylesheet.css" rel="noreferrer noopener">stylesheet.css</a>" <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/css</span>"&gt;</span></td></tr><tr><td class="line-number" value="13"></td><td class="line-content"></td></tr><tr><td class="line-number" value="14"></td><td class="line-content"><span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://polyfill.io/v3/polyfill.min.js?features=es6" rel="noreferrer noopener">https://polyfill.io/v3/polyfill.min.js?features=es6</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="15"></td><td class="line-content"><span class="html-tag">&lt;script <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/javascript</span>" <span class="html-attribute-name">id</span>="<span class="html-attribute-value">MathJax-script</span>" <span class="html-attribute-name">async</span> <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" rel="noreferrer noopener">https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="16"></td><td class="line-content"><span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="17"></td><td class="line-content">window.MathJax = {</td></tr><tr><td class="line-number" value="18"></td><td class="line-content">  tex: {</td></tr><tr><td class="line-number" value="19"></td><td class="line-content">    inlineMath: [ ['$','$'],['\\(','\\)'] ],</td></tr><tr><td class="line-number" value="20"></td><td class="line-content">    displayMath: [ ['$$','$$'], ['\\[','\\]'] ],</td></tr><tr><td class="line-number" value="21"></td><td class="line-content">    processEscapes: true,      </td></tr><tr><td class="line-number" value="22"></td><td class="line-content">    processEnvironments: true, </td></tr><tr><td class="line-number" value="23"></td><td class="line-content">    processRefs: true       </td></tr><tr><td class="line-number" value="24"></td><td class="line-content">  },</td></tr><tr><td class="line-number" value="25"></td><td class="line-content">  options: {</td></tr><tr><td class="line-number" value="26"></td><td class="line-content">   ignoreHtmlClass: 'tex2jax_ignore|editor-rich-text'</td></tr><tr><td class="line-number" value="27"></td><td class="line-content">  }</td></tr><tr><td class="line-number" value="28"></td><td class="line-content">};</td></tr><tr><td class="line-number" value="29"></td><td class="line-content"><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="30"></td><td class="line-content"></td></tr><tr><td class="line-number" value="31"></td><td class="line-content"></td></tr><tr><td class="line-number" value="32"></td><td class="line-content"><span class="html-tag">&lt;title&gt;</span>Pan Xu<span class="html-tag">&lt;/title&gt;</span></td></tr><tr><td class="line-number" value="33"></td><td class="line-content"><span class="html-tag">&lt;/head&gt;</span></td></tr><tr><td class="line-number" value="34"></td><td class="line-content"></td></tr><tr><td class="line-number" value="35"></td><td class="line-content"><span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="36"></td><td class="line-content">	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){</td></tr><tr><td class="line-number" value="37"></td><td class="line-content">	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),</td></tr><tr><td class="line-number" value="38"></td><td class="line-content">	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)</td></tr><tr><td class="line-number" value="39"></td><td class="line-content">	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');</td></tr><tr><td class="line-number" value="40"></td><td class="line-content">	</td></tr><tr><td class="line-number" value="41"></td><td class="line-content">	ga('create', 'UA-54048675-2', 'auto');</td></tr><tr><td class="line-number" value="42"></td><td class="line-content">	ga('send', 'pageview');</td></tr><tr><td class="line-number" value="43"></td><td class="line-content"><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="44"></td><td class="line-content"></td></tr><tr><td class="line-number" value="45"></td><td class="line-content"></td></tr><tr><td class="line-number" value="46"></td><td class="line-content"><span class="html-tag">&lt;nav <span class="html-attribute-name">class</span>="<span class="html-attribute-value">navbar sticky-top navbar-expand-lg navbar-light bg-light</span>"&gt;</span></td></tr><tr><td class="line-number" value="47"></td><td class="line-content">	<span class="html-tag">&lt;a <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-link</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/panxu-ai.github.io" rel="noreferrer noopener">panxu-ai.github.io</a>"&gt;</span><span class="html-tag">&lt;b&gt;</span><span class="html-tag">&lt;font <span class="html-attribute-name">size</span>="<span class="html-attribute-value">+3</span>" <span class="html-attribute-name">color</span>=<span class="html-attribute-value">black</span> <span class="html-attribute-name">face</span>="<span class="html-attribute-value">AREIAL,sans-serif</span>"&gt;</span><span class="html-tag">&lt;big&gt;</span>Pan Xu<span class="html-tag">&lt;/big&gt;</span><span class="html-tag">&lt;/font&gt;</span><span class="html-tag">&lt;/b&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="48"></td><td class="line-content">	<span class="html-tag">&lt;button <span class="html-attribute-name">class</span>="<span class="html-attribute-value">navbar-toggler</span>" <span class="html-attribute-name">type</span>="<span class="html-attribute-value">button</span>" <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">data-target</span>="<span class="html-attribute-value">#navbarSupportedContent</span>" <span class="html-attribute-name">aria-controls</span>="<span class="html-attribute-value">navbarSupportedContent</span>" <span class="html-attribute-name">aria-expanded</span>="<span class="html-attribute-value">false</span>" <span class="html-attribute-name">aria-label</span>="<span class="html-attribute-value">Toggle navigation</span>"&gt;</span></td></tr><tr><td class="line-number" value="49"></td><td class="line-content">	  <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">navbar-toggler-icon</span>"&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="50"></td><td class="line-content">	<span class="html-tag">&lt;/button&gt;</span></td></tr><tr><td class="line-number" value="51"></td><td class="line-content">	<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">collapse navbar-collapse</span>" <span class="html-attribute-name">id</span>="<span class="html-attribute-value">navbarSupportedContent</span>"&gt;</span>        </td></tr><tr><td class="line-number" value="52"></td><td class="line-content">	<span class="html-tag">&lt;ul <span class="html-attribute-name">class</span>="<span class="html-attribute-value">navbar-nav mr-auto</span>"&gt;</span></td></tr><tr><td class="line-number" value="53"></td><td class="line-content">		<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-item</span>"&gt;</span></td></tr><tr><td class="line-number" value="54"></td><td class="line-content">		<span class="html-tag">&lt;a <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-link</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/panxu-ai.github.io" rel="noreferrer noopener">panxu-ai.github.io</a>"&gt;</span><span class="html-tag">&lt;font <span class="html-attribute-name">size</span>="<span class="html-attribute-value">5</span>"&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;Home<span class="html-tag">&lt;/font&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="55"></td><td class="line-content">		<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="56"></td><td class="line-content">		<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-item active</span>"&gt;</span></td></tr><tr><td class="line-number" value="57"></td><td class="line-content">		<span class="html-tag">&lt;a <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-link</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication" rel="noreferrer noopener">publication</a>"&gt;</span><span class="html-tag">&lt;font <span class="html-attribute-name">size</span>="<span class="html-attribute-value">5</span>"&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;Publications<span class="html-tag">&lt;/font&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">sr-only</span>"&gt;</span>(current)<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="58"></td><td class="line-content">		<span class="html-tag">&lt;/li&gt;</span>        </td></tr><tr><td class="line-number" value="59"></td><td class="line-content">		<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-item</span>"&gt;</span></td></tr><tr><td class="line-number" value="60"></td><td class="line-content">		<span class="html-tag">&lt;a <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-link</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/teaching" rel="noreferrer noopener">teaching</a>"&gt;</span><span class="html-tag">&lt;font <span class="html-attribute-name">size</span>="<span class="html-attribute-value">5</span>"&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;Teaching<span class="html-tag">&lt;/font&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="61"></td><td class="line-content">		<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="62"></td><td class="line-content">		<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-item</span>"&gt;</span></td></tr><tr><td class="line-number" value="63"></td><td class="line-content">		<span class="html-tag">&lt;a <span class="html-attribute-name">class</span>="<span class="html-attribute-value">nav-link</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/service" rel="noreferrer noopener">service</a>"&gt;</span><span class="html-tag">&lt;font <span class="html-attribute-name">size</span>="<span class="html-attribute-value">5</span>"&gt;</span>&amp;nbsp;&amp;nbsp;&amp;nbsp;Services<span class="html-tag">&lt;/font&gt;</span><span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="64"></td><td class="line-content">		<span class="html-tag">&lt;/li&gt;</span>			</td></tr><tr><td class="line-number" value="65"></td><td class="line-content">	<span class="html-tag">&lt;/ul&gt;</span>	 </td></tr><tr><td class="line-number" value="66"></td><td class="line-content">	<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">float: left</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/myname" rel="noreferrer noopener">myname</a>"&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://panxu-ai.github.io/image/name_ch.png" rel="noreferrer noopener">image/name_ch.png</a>" <span class="html-attribute-name">width</span>="<span class="html-attribute-value">90</span>"&gt;</span><span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="67"></td><td class="line-content">	<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="68"></td><td class="line-content"><span class="html-tag">&lt;/nav&gt;</span></td></tr><tr><td class="line-number" value="69"></td><td class="line-content"></td></tr><tr><td class="line-number" value="70"></td><td class="line-content"><span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="71"></td><td class="line-content"></td></tr><tr><td class="line-number" value="72"></td><td class="line-content"></td></tr><tr><td class="line-number" value="73"></td><td class="line-content"><span class="html-comment">&lt;!-- </span></td></tr><tr><td class="line-number" value="74"></td><td class="line-content"><span class="html-comment">&lt;p&gt;&lt;h3&gt;Journals&lt;/h3&gt;&lt;/p&gt; </span></td></tr><tr><td class="line-number" value="75"></td><td class="line-content"><span class="html-comment">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="76"></td><td class="line-content"><span class="html-comment">	</span></td></tr><tr><td class="line-number" value="77"></td><td class="line-content"><span class="html-comment">&lt;/ul&gt; --&gt;</span></td></tr><tr><td class="line-number" value="78"></td><td class="line-content"></td></tr><tr><td class="line-number" value="79"></td><td class="line-content"><span class="html-tag">&lt;p&gt;</span><span class="html-tag">&lt;h5&gt;</span>PUBLICATIONS<span class="html-tag">&lt;/h5&gt;</span></td></tr><tr><td class="line-number" value="80"></td><td class="line-content">  <span class="html-tag">&lt;p&gt;</span>Full publication list on <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://scholar.google.com/citations?user=UkYBx6YAAAAJ&amp;hl=en" rel="noreferrer noopener">https://scholar.google.com/citations?user=UkYBx6YAAAAJ&amp;hl=en</a>" <span class="html-attribute-name">target</span>="<span class="html-attribute-value">_blank</span>"&gt;</span>Google Scholar<span class="html-tag">&lt;/a&gt;</span>.</td></tr><tr><td class="line-number" value="81"></td><td class="line-content">  <span class="html-tag">&lt;sup&gt;</span>*<span class="html-tag">&lt;/sup&gt;</span> indicates equal contribution.</td></tr><tr><td class="line-number" value="82"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="83"></td><td class="line-content"><span class="html-tag">&lt;/p&gt;</span> 	  </td></tr><tr><td class="line-number" value="84"></td><td class="line-content"><span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="85"></td><td class="line-content">	<span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Langevin Monte Carlo for Contextual Bandits<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="86"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Hongkai Zheng, Eric Mazumdar, Kamyar Azizzadenesheli, Anima Anandkumar<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="87"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 39th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Baltimore, Maryland, USA, 2022.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="88"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2022langevin-abstract" rel="noreferrer noopener">#xu2022langevin-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/2206.11254" rel="noreferrer noopener">https://arxiv.org/abs/2206.11254</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/devzhk/LMCTS" rel="noreferrer noopener">https://github.com/devzhk/LMCTS</a>"&gt;</span>Code<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="89"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="90"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2022langevin-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose an efficient posterior sampling algorithm, viz., Langevin Monte Carlo Thompson Sampling (LMC-TS), that uses Markov Chain Monte Carlo (MCMC) methods to directly sample from the posterior distribution in contextual bandits. Our method is computationally efficient since it only needs to perform noisy gradient descent updates without constructing the Laplace approximation of the posterior distribution. We prove that the proposed algorithm achieves the same sublinear regret bound as the best Thompson sampling algorithms for a special case of contextual bandits, viz., linear contextual bandits. We conduct experiments on both synthetic data and real-world datasets on different contextual bandit models, which demonstrates that directly sampling from the posterior is both computationally efficient and competitive in performance.</td></tr><tr><td class="line-number" value="91"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="92"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="93"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="94"></td><td class="line-content"></td></tr><tr><td class="line-number" value="95"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Neural Contextual Bandits with Deep Representation and Shallow Exploration<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="96"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Zheng Wen, Handong Zhao, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="97"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 10th International Conference on Learning Representations (<span class="html-tag">&lt;b&gt;</span>ICLR<span class="html-tag">&lt;/b&gt;</span>), Online, 2022.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="98"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2022neural-abstract" rel="noreferrer noopener">#xu2022neural-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://openreview.net/forum?id=xnYACQquaGV" rel="noreferrer noopener">https://openreview.net/forum?id=xnYACQquaGV</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://openreview.net/attachment?id=xnYACQquaGV&amp;name=supplementary_material" rel="noreferrer noopener">https://openreview.net/attachment?id=xnYACQquaGV&amp;name=supplementary_material</a>"&gt;</span>Code<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="99"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="100"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2022neural-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We study neural contextual bandits, a general class of contextual bandits, where each context-action pair is associated with a raw feature vector, but the specific reward generating function is unknown. We propose a novel learning algorithm that transforms the raw feature vector using the last hidden layer of a deep ReLU neural network (deep representation learning), and uses an upper confidence bound (UCB) approach to explore in the last linear layer (shallow exploration). We prove that under standard assumptions, our proposed algorithm achieves $\widetilde{O}(\sqrt{T})$ finite-time regret, where $T$ is the learning time horizon. Compared with existing neural contextual bandit algorithms, our approach is computationally much more efficient since it only needs to explore in the last layer of the deep neural network.</td></tr><tr><td class="line-number" value="101"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="102"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="103"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="104"></td><td class="line-content"></td></tr><tr><td class="line-number" value="105"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Adaptive Sampling for Heterogeneous Rank Aggregation from Noisy Pairwise Comparisons<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="106"></td><td class="line-content">Yue Wu*, Tao Jin*, Hao Lou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Farzad Farnoud, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="107"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 25th International Conference on Artificial Intelligence and Statistics (<span class="html-tag">&lt;b&gt;</span>AISTATS<span class="html-tag">&lt;/b&gt;</span>), Online, 2022.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="108"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#wu2022adaptive-abstract" rel="noreferrer noopener">#wu2022adaptive-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/2110.04136" rel="noreferrer noopener">https://arxiv.org/abs/2110.04136</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="109"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="110"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">wu2022adaptive-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>In heterogeneous rank aggregation problems, users often exhibit various accuracy levels when comparing pairs of items. Thus, a uniform querying strategy over users may not be optimal. To address this issue, we propose an elimination-based active sampling strategy, which estimates the ranking of items via noisy pairwise comparisons from multiple users and improves the users' average accuracy by maintaining an active set of users. We prove that our algorithm can return the true ranking of items with high probability. We also provide a sample complexity bound for the proposed algorithm, which outperforms the non-active strategies in the literature and close to oracle under mild conditions. Experiments are provided to show the empirical advantage of the proposed methods over the state-of-the-art baselines.</td></tr><tr><td class="line-number" value="111"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="112"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="113"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="114"></td><td class="line-content"></td></tr><tr><td class="line-number" value="115"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Evaluation of individual and ensemble probabilistic forecasts of COVID-19 mortality in the US<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="116"></td><td class="line-content">Estee Y Cramer, ... , <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, ... , Nicholas G. Reich. <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="117"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>Proceedings of the National Academy of Sciences (<span class="html-tag">&lt;b&gt;</span>PNAS<span class="html-tag">&lt;/b&gt;</span>), Volume 119, No. 15, 2022.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="118"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#cramer2022evaluation-abstract" rel="noreferrer noopener">#cramer2022evaluation-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.pnas.org/doi/10.1073/pnas.2113561119" rel="noreferrer noopener">https://www.pnas.org/doi/10.1073/pnas.2113561119</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="119"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="120"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">cramer2022evaluation-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>This paper compares the probabilistic accuracy of short-term forecasts of reported deaths due to COVID-19 during the first year and a half of the pandemic in the United States. Results show high variation in accuracy between and within stand-alone models and more consistent accuracy from an ensemble model that combined forecasts from all eligible models. This demonstrates that an ensemble model provided a reliable and comparatively accurate means of forecasting deaths during the COVID-19 pandemic that exceeded the performance of all of the models that contributed to it. This work strengthens the evidence base for synthesizing multiple models to support public-health action.</td></tr><tr><td class="line-number" value="121"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="122"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span>  	</td></tr><tr><td class="line-number" value="123"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="124"></td><td class="line-content"></td></tr><tr><td class="line-number" value="125"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Double Explore-then-Commit: Asymptotic Optimality and Beyond<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="126"></td><td class="line-content">Tianyuan Jin, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Xiaokui Xiao, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="127"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 34th Annual Conference on Learning Theory (<span class="html-tag">&lt;b&gt;</span>COLT<span class="html-tag">&lt;/b&gt;</span>), Online, 2021.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="128"></td><td class="line-content">This work has been presented at the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://offline-rl-neurips.github.io/" rel="noreferrer noopener">https://offline-rl-neurips.github.io/</a>"&gt;</span>NeurIPS 2020 Offline Reinforcement Learning Workshop<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span>.<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="129"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#jin2021double-abstract" rel="noreferrer noopener">#jin2021double-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.mlr.press/v134/jin21a" rel="noreferrer noopener">https://proceedings.mlr.press/v134/jin21a</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="130"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="131"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">jin2021double-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose a double explore-then-commit (DETC) algorithm that has two exploration and exploitation phases and show that it  can achieve the asymptotically optimal regret bound. To our knowledge, DETC is the first non-fully-sequential algorithm that achieves asymptotic optimality. In addition, we extend DETC to batched bandit problems, where (i) the exploration process is split into a small number of batches and (ii) the round complexity is of central interest. We prove that a batched version of DETC can achieve the asymptotic optimality with only a constant round complexity. This is the first batched bandit algorithm that can attain the optimal asymptotic regret bound and optimal round complexity simultaneously.</td></tr><tr><td class="line-number" value="132"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="133"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="134"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="135"></td><td class="line-content"></td></tr><tr><td class="line-number" value="136"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Faster Convergence of Stochastic Gradient Langevin Dynamics for Non-Log-Concave Sampling<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="137"></td><td class="line-content">Difan Zou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="138"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 37th International Conference on Uncertainty in Artificial Intelligence (<span class="html-tag">&lt;b&gt;</span>UAI<span class="html-tag">&lt;/b&gt;</span>), Online, 2021.<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="139"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zou2021faster-abstract" rel="noreferrer noopener">#zou2021faster-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.mlr.press/v161/zou21a.html" rel="noreferrer noopener">https://proceedings.mlr.press/v161/zou21a.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="140"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="141"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zou2021faster-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We provide a new  convergence analysis of stochastic gradient Langevin dynamics (SGLD) for sampling from a class of distributions that can be non-log-concave.  At the core of our approach is a novel conductance analysis of SGLD using an auxiliary time-reversible Markov Chain. Under certain conditions on the target distribution, we prove that $\widetilde O(d^4\epsilon^{-2})$ stochastic gradient evaluations suffice to guarantee $\epsilon$-sampling error in terms of the total variation distance, where $d$ is the problem dimension. This improves existing results on the convergence rate of SGLD \citep{raginsky2017non,xu2018global}. We further show that provided an additional Hessian Lipschitz condition on the log-density function, SGLD is guaranteed to achieve $\epsilon$-sampling error within $\widetilde O(d^{15/4}\epsilon^{-3/2})$ stochastic gradient evaluations. Our proof technique provides a new way to study the convergence of Langevin based algorithms, and sheds some light on the design of fast stochastic gradient based sampling algorithms.</td></tr><tr><td class="line-number" value="142"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="143"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="144"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="145"></td><td class="line-content"></td></tr><tr><td class="line-number" value="146"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>MOTS: Minimax Optimal Thompson Sampling<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="147"></td><td class="line-content">Tianyuan Jin, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Jieming Shi, Xiaokui Xiao, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="148"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 38th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Online, 2021.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="149"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#jin2021mots-abstract" rel="noreferrer noopener">#jin2021mots-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.mlr.press/v139/jin21d.html" rel="noreferrer noopener">https://proceedings.mlr.press/v139/jin21d.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="150"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="151"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">jin2021mots-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>Thompson sampling is one of the most widely used algorithms for many online decision problems, due to its simplicity in implementation and superior empirical performance over other state-of-the-art methods. Despite its popularity and empirical success, it has remained an open problem whether Thompson sampling can match the minimax lower bound $\Omega(\sqrt{KT})$ for $K$-armed bandit problems, where $T$ is the total time horizon. In this paper, we solve this long open problem by proposing a variant of Thompson sampling called MOTS that adaptively clips the sampling instance of the chosen arm at each time step. We prove that this simple variant of Thompson sampling achieves the minimax optimal regret bound $O(\sqrt{KT})$ for finite time horizon $T$, as well as the asymptotic optimal regret bound for Gaussian rewards when $T$ approaches infinity. To our knowledge, MOTS is the first Thompson sampling type algorithm that achieves the minimax optimality for multi-armed bandit problems.</td></tr><tr><td class="line-number" value="152"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="153"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="154"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="155"></td><td class="line-content"></td></tr><tr><td class="line-number" value="156"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Almost Optimal Anytime Algorithm for Batched Multi-Armed Bandits<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="157"></td><td class="line-content">Tianyuan Jin, Jing Tang, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Keke Huang, Xiaokui Xiao, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="158"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 38th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Online, 2021.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="159"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#jin2021almost-abstract" rel="noreferrer noopener">#jin2021almost-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.mlr.press/v139/jin21c.html" rel="noreferrer noopener">https://proceedings.mlr.press/v139/jin21c.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="160"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="161"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">jin2021almost-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>In batched multi-armed bandit problems, the learner can adaptively pull arms and adjust strategy in batches. In many real applications, not only the regret but also the batch complexity need to be optimized. Existing batched bandit algorithms usually assume that the time horizon $T$ is known in advance. However, many applications involve an unpredictable stopping time. In this paper, we study the anytime batched multi-armed bandit problem. We propose an anytime algorithm that achieves the asymptotically optimal regret for exponential families of reward distributions with $\mathcal{O}(\log \log T\cdot \ilog^{\alpha} (T))$ batches, where $\alpha\in \mathcal{O}_{T}(1)$. Moreover, we prove that for any constant $c&gt;0$, no algorithm can achieve the asymptotically optimal regret within $c \log \log T$ batches.</td></tr><tr><td class="line-number" value="162"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="163"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="164"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="165"></td><td class="line-content"></td></tr><tr><td class="line-number" value="166"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="167"></td><td class="line-content">Yue Wu, Weitong Zhang, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="168"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 33rd Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NeurIPS<span class="html-tag">&lt;/b&gt;</span>), Online, 2020.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="169"></td><td class="line-content">This work has been presented at the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://wensun.github.io/rl_theory_workshop_2020_ICML.github.io/" rel="noreferrer noopener">https://wensun.github.io/rl_theory_workshop_2020_ICML.github.io/</a>"&gt;</span>ICML 2020 Theoretical Foundations of Reinforcement Learning Workshop.<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="170"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#wu2020finite-abstract" rel="noreferrer noopener">#wu2020finite-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/cc9b3c69b56df284846bf2432f1cba90-Abstract.html" rel="noreferrer noopener">https://proceedings.neurips.cc/paper/2020/hash/cc9b3c69b56df284846bf2432f1cba90-Abstract.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="171"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="172"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">wu2020finite-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We provide a non-asymptotic analysis for two time-scale actor-critic methods under non-i.i.d. setting. We prove that the actor-critic method is guaranteed to find a first-order stationary point (i.e., $\|\nabla J(\theta)\|_2^2 \le \epsilon$) of the non-concave performance function $J({\theta})$, with $\mathcal{\widetilde{O}}(\epsilon^{-2.5})$ sample complexity. To the best of our knowledge, this is the first work providing finite-time analysis and sample complexity bound for two time-scale actor-critic methods.</td></tr><tr><td class="line-number" value="173"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="174"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="175"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="176"></td><td class="line-content"></td></tr><tr><td class="line-number" value="177"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="178"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="179"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 37th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Online, 2020.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="180"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2020finite-abstract" rel="noreferrer noopener">#xu2020finite-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v119/xu20c.html" rel="noreferrer noopener">http://proceedings.mlr.press/v119/xu20c.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="181"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="182"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2020finite-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We present a finite-time analysis of a neural Q-learning algorithm, where the data are generated from a Markov decision process, and the action-value function is approximated by a deep ReLU neural network. We prove that neural Q-learning finds the optimal policy with an $O(1/\sqrt{T})$ convergence rate if the neural function approximator is sufficiently overparameterized, where $T$ is the number of iterations. To our best knowledge, our result is the first finite-time analysis of neural Q-learning under non-i.i.d. data assumption.</td></tr><tr><td class="line-number" value="183"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="184"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="185"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="186"></td><td class="line-content"></td></tr><tr><td class="line-number" value="187"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Nested Variance Reduction for Nonconvex Optimization<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="188"></td><td class="line-content">Dongruo Zhou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="189"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>Journal of Machine Learning Research (<span class="html-tag">&lt;b&gt;</span>JMLR<span class="html-tag">&lt;/b&gt;</span>), Volume 21, No. 103, 2020.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="190"></td><td class="line-content">The <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2018stochastic-neurips" rel="noreferrer noopener">#zhou2018stochastic-neurips</a>"&gt;</span>short version<span class="html-tag">&lt;/a&gt;</span> of this paper has been published in NeurIPS 2018. The journal version extends the original SNVRG algorithm for finding first order stationary points to local minimum finding algorithms by incorporating this manuscript: <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1806.08782" rel="noreferrer noopener">https://arxiv.org/abs/1806.08782</a>"&gt;</span>Finding Local Minima via Stochastic Nested Variance Reduction<span class="html-tag">&lt;/a&gt;</span>. <span class="html-tag">&lt;br&gt;</span>  </td></tr><tr><td class="line-number" value="191"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2020stochastic-abstract" rel="noreferrer noopener">#zhou2020stochastic-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.jmlr.org/papers/v21/18-447.html" rel="noreferrer noopener">https://www.jmlr.org/papers/v21/18-447.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="192"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="193"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2020stochastic-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>In this journal version of SNVRG, we further propose two algorithms that can find local minima faster than state-of-the-art algorithms in both finite-sum and general stochastic (online) nonconvex optimization. In particular, for finite-sum optimization problems, the proposed $\text{SNVRG}+\text{Neon2}^{\text{finite}}$ algorithm achieves $\tilde{O}(n^{1/2}\epsilon^{-2}+n\epsilon_H^{-3}+n^{3/4}\epsilon_H^{-7/2})$ gradient complexity to converge to an $(\epsilon, \epsilon_H)$-second-order stationary point, which outperforms $\text{SVRG}+\text{Neon2}^{\text{finite}}$ \citep{allen2018neon2}, the best existing algorithm, in a wide regime. For general stochastic optimization problems, the proposed $\text{SNVRG}+\text{Neon2}^{\text{online}}$ achieves $\tilde{O}(\epsilon^{-3}+\epsilon_H^{-5}+\epsilon^{-2}\epsilon_H^{-3})$ gradient complexity, which is better than both $\text{SVRG}+\text{Neon2}^{\text{online}}$ \citep{allen2018neon2} and Natasha2 \citep{allen2017natasha2} in certain regimes. </td></tr><tr><td class="line-number" value="194"></td><td class="line-content">  Thorough experimental results on different nonconvex optimization problems back up our theory.</td></tr><tr><td class="line-number" value="195"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="196"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="197"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="198"></td><td class="line-content"></td></tr><tr><td class="line-number" value="199"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">jin2020rank</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Sample Efficient Policy Gradient Methods with Recursive Variance Reduction<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="200"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Felicia Gao, Quanquan Gu<span class="html-tag">&lt;br&gt;</span> </td></tr><tr><td class="line-number" value="201"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 8th International Conference on Learning Representations (<span class="html-tag">&lt;b&gt;</span>ICLR<span class="html-tag">&lt;/b&gt;</span>), Addis Ababa, Ethiopia, 2020.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="202"></td><td class="line-content">Partial results of this work have been presented at the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://optrl2019.github.io/" rel="noreferrer noopener">https://optrl2019.github.io/</a>"&gt;</span> NeurIPS 2019 Optimization Foundations of Reinforcement Learning Workshop<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span>, Vancouver, Canada, 2019 and the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://sites.google.com/view/RL4RealLife#h.p_E8GavvJ-X7nT" rel="noreferrer noopener">https://sites.google.com/view/RL4RealLife#h.p_E8GavvJ-X7nT</a>"&gt;</span>2020 Virtual Conference on Reinforcement Learning for Real Life.<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="203"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2020sample-abstract" rel="noreferrer noopener">#xu2020sample-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1909.08610" rel="noreferrer noopener">https://arxiv.org/abs/1909.08610</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/paper/poster_neurips19_optrl_srvrpg_portrait.pdf" rel="noreferrer noopener">paper/poster_neurips19_optrl_srvrpg_portrait.pdf</a>"&gt;</span>Poster<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/xgfelicia/SRVRPG" rel="noreferrer noopener">https://github.com/xgfelicia/SRVRPG</a>"&gt;</span>Code<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://youtu.be/9fj6LEyaX-k" rel="noreferrer noopener">https://youtu.be/9fj6LEyaX-k</a>"&gt;</span>Video<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="204"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="205"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2020sample-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose a novel policy gradient algorithm called SRVR-PG, which only requires $O(1/\epsilon^{3/2})$ episodes to find an $\epsilon$-approximate stationary point of the nonconcave performance function $J(\boldsymbol{\theta})$ (i.e., $\boldsymbol{\theta}$ such that $\|\nabla J(\boldsymbol{\theta})\|_2^2\leq\epsilon$). This sample complexity improves the existing result $O(1/\epsilon^{5/3})$ for stochastic variance reduced policy gradient algorithms by a factor of $O(1/\epsilon^{1/6})$. In addition, we also propose a variant of SRVR-PG with parameter exploration, which explores the initial policy parameter from a prior probability distribution. We conduct numerical experiments on classic control problems in reinforcement learning to validate the performance of our proposed algorithms.</td></tr><tr><td class="line-number" value="206"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="207"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="208"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="209"></td><td class="line-content"></td></tr><tr><td class="line-number" value="210"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Rank Aggregation via Heterogeneous Thurstone Preference Models<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="211"></td><td class="line-content">Tao Jin*, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Quanquan Gu, Farzad Farnoud<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="212"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 34th Conference on Artificial Intelligence (<span class="html-tag">&lt;b&gt;</span>AAAI<span class="html-tag">&lt;/b&gt;</span>), New York, New York, USA, 2020.<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publish-type</span>"&gt;</span>[Oral presentation, 4.5%]<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="213"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#jin2020rank-abstract" rel="noreferrer noopener">#jin2020rank-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://aaai.org/ojs/index.php/AAAI/article/view/5860" rel="noreferrer noopener">https://aaai.org/ojs/index.php/AAAI/article/view/5860</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/tao-j/hra" rel="noreferrer noopener">https://github.com/tao-j/hra</a>"&gt;</span>Code<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="214"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="215"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">jin2020rank-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose the Heterogeneous Thurstone Model (HTM) for aggregating ranked data, which can take the accuracy levels of different users into account. By allowing different noise distributions, the proposed HTM model maintains the generality of Thurstone's original framework, and as such, also extends the Bradley-Terry-Luce (BTL) model for pairwise comparisons to heterogeneous populations of users. Under this framework, we also propose a rank aggregation algorithm based on alternating gradient descent to estimate the underlying item scores and accuracy levels of different users simultaneously from noisy pairwise comparisons. We theoretically prove that the proposed algorithm converges linearly up to a statistical error which matches that of the state-of-the-art method for the single-user BTL model. We evaluate the  proposed HTM model and algorithm on both synthetic and real data, demonstrating that it outperforms existing methods.</td></tr><tr><td class="line-number" value="216"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="217"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="218"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="219"></td><td class="line-content"><span class="html-comment">&lt;!-- &lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="220"></td><td class="line-content"><span class="html-comment"></span></td></tr><tr><td class="line-number" value="221"></td><td class="line-content"><span class="html-comment">&lt;p&gt;&lt;h3&gt;2019&lt;/h3&gt;	</span></td></tr><tr><td class="line-number" value="222"></td><td class="line-content"><span class="html-comment">&lt;ul&gt; --&gt;</span></td></tr><tr><td class="line-number" value="223"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Gradient Hamiltonian Monte Carlo Methods with Recursive Variance Reduction<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="224"></td><td class="line-content">Difan Zou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="225"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 32nd Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NeurIPS<span class="html-tag">&lt;/b&gt;</span>), Vancouver, Canada, 2019.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="226"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zou2019stochastic-abstract" rel="noreferrer noopener">#zou2019stochastic-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://papers.nips.cc/paper/2019/hash/c3535febaff29fcb7c0d20cbe94391c7-Abstract.html" rel="noreferrer noopener">https://papers.nips.cc/paper/2019/hash/c3535febaff29fcb7c0d20cbe94391c7-Abstract.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/paper/poster_neurips19_sghmc.pdf" rel="noreferrer noopener">paper/poster_neurips19_sghmc.pdf</a>"&gt;</span>Poster<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="227"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="228"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zou2019stochastic-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span></td></tr><tr><td class="line-number" value="229"></td><td class="line-content">    Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) algorithms have received increasing attention in both theory and practice. In this paper, we propose a Stochastic Recursive Variance-Reduced gradient HMC (SRVR-HMC) algorithm. It makes use of a semi-stochastic gradient estimator that recursively accumulates the gradient information to reduce the variance of the stochastic gradient. We provide a convergence analysis of SRVR-HMC for sampling from a class of non-log-concave distributions and show that SRVR-HMC converges faster than all existing HMC-type algorithms based on underdamped Langevin dynamics. Thorough experiments on synthetic and real-world datasets validate our theory and demonstrate the superiority of SRVR-HMC.</td></tr><tr><td class="line-number" value="230"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="231"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span>    </td></tr><tr><td class="line-number" value="232"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="233"></td><td class="line-content"></td></tr><tr><td class="line-number" value="234"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2019improved</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Variance-Reduced Cubic Regularization Methods<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="235"></td><td class="line-content">Dongruo Zhou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="236"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>Journal of Machine Learning Research (<span class="html-tag">&lt;b&gt;</span>JMLR<span class="html-tag">&lt;/b&gt;</span>), Volume 20, No. 134, 2019.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="237"></td><td class="line-content">The <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2018stochastic-icml" rel="noreferrer noopener">#zhou2018stochastic-icml</a>"&gt;</span>short version<span class="html-tag">&lt;/a&gt;</span> of this paper has been published in ICML 2018. The journal version extends the SVRC algorithm to a sample-efficient one proposed in this manuscript: <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1811.11989" rel="noreferrer noopener">https://arxiv.org/abs/1811.11989</a>"&gt;</span>Sample Efficient Stochastic Variance-Reduced Cubic Regularization Method<span class="html-tag">&lt;/a&gt;</span>. <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="238"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2019stochastic-abstract" rel="noreferrer noopener">#zhou2019stochastic-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://jmlr.org/papers/v20/19-055.html" rel="noreferrer noopener">https://jmlr.org/papers/v20/19-055.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="239"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="240"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2019stochastic-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>To reduce the sample complexity of Hessian matrix computation in SVRC, we also propose a sample efficient stochastic variance-reduced cubic regularization (Lite-SVRC) algorithm for finding the local minimum more efficiently. Lite-SVRC converges to an $(\epsilon,\sqrt{\epsilon})$-approximate local minimum within $\tilde{O}(n+n^{2/3}/\epsilon^{3/2})$ Hessian sample complexity, which is faster than all existing cubic regularization based methods. Numerical experiments with different nonconvex optimization problems conducted on real datasets validate our theoretical results for both SVRC and Lite-SVRC. </td></tr><tr><td class="line-number" value="241"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="242"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span>  </td></tr><tr><td class="line-number" value="243"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="244"></td><td class="line-content"></td></tr><tr><td class="line-number" value="245"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>An Improved Convergence Analysis of Stochastic Variance-Reduced Policy Gradient<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="246"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Felicia Gao, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="247"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 35th International Conference on Uncertainty in Artificial Intelligence (<span class="html-tag">&lt;b&gt;</span>UAI<span class="html-tag">&lt;/b&gt;</span>), Tel Aviv, Israel, 2019. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publish-type</span>"&gt;</span>[Oral presentation, 7.8%]<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="248"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2019improved-abstract" rel="noreferrer noopener">#xu2019improved-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1905.12615" rel="noreferrer noopener">https://arxiv.org/abs/1905.12615</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="249"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="250"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2019improved-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We revisit the stochastic variance-reduced policy gradient (SVRPG) method proposed by \citet{papini2018stochastic} for reinforcement learning. We provide an improved convergence analysis of SVRPG and show that it can find an $\epsilon$-approximate stationary point of the performance function within $O(1/\epsilon^{5/3})$ trajectories. This sample complexity improves upon the best known result $O(1/\epsilon^2)$ by a factor of $O(1/\epsilon^{1/3})$. At the core of our analysis is (i) a tighter upper bound for the variance of importance sampling weights, where we prove that the variance can be controlled by the parameter distance between different policies; and (ii) a fine-grained analysis of the epoch length and batch size parameters such that we can significantly reduce the number of trajectories required in each iteration of SVRPG. We also empirically demonstrate the effectiveness of our theoretical claims of batch sizes on  reinforcement learning benchmark tasks. </td></tr><tr><td class="line-number" value="251"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="252"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="253"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="254"></td><td class="line-content"></td></tr><tr><td class="line-number" value="255"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2018global</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Sampling from Non-Log-Concave Distributions via Variance-Reduced Gradient Langevin Dynamics<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="256"></td><td class="line-content">Difan Zou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="257"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 22nd International Conference on Artificial Intelligence and Statistics (<span class="html-tag">&lt;b&gt;</span>AISTATS<span class="html-tag">&lt;/b&gt;</span>), Naha, Okinawa, Japan, 2019. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="258"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zou2019sampling-abstract" rel="noreferrer noopener">#zou2019sampling-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v89/zou19a.html" rel="noreferrer noopener">http://proceedings.mlr.press/v89/zou19a.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="259"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="260"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zou2019sampling-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We study stochastic variance reduction-based Langevin dynamic algorithms, SVRG-LD and SAGA-LD \citep{dubey2016variance}, for sampling from non-log-concave distributions. Under certain assumptions on the log density function, we establish the convergence guarantees of SVRG-LD and SAGA-LD in $2$-Wasserstein distance. More specifically, we show that both SVRG-LD and SAGA-LD require $ \tilde O\big(n+n^{3/4}/\epsilon^2 + n^{1/2}/\epsilon^4\big)\cdot \exp\big(\tilde O(d+\gamma)\big)$ stochastic gradient evaluations to achieve $\epsilon$-accuracy in $2$-Wasserstein distance, which outperforms the $ \tilde O\big(n/\epsilon^4\big)\cdot \exp\big(\tilde O(d+\gamma)\big)$ gradient complexity achieved by Langevin Monte Carlo Method \citep{raginsky2017non}. Experiments on synthetic data and real data back up our theory.</td></tr><tr><td class="line-number" value="261"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="262"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="263"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="264"></td><td class="line-content"><span class="html-comment">&lt;!-- &lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="265"></td><td class="line-content"><span class="html-comment"></span></td></tr><tr><td class="line-number" value="266"></td><td class="line-content"><span class="html-comment">&lt;p&gt;&lt;h3&gt;2018&lt;/h3&gt;	</span></td></tr><tr><td class="line-number" value="267"></td><td class="line-content"><span class="html-comment">&lt;ul&gt;	 --&gt;</span>	</td></tr><tr><td class="line-number" value="268"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="269"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Jinghui Chen*, Difan Zou, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="270"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 31st Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NeurIPS<span class="html-tag">&lt;/b&gt;</span>), Montréal, Canada, 2018.<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publish-type</span>"&gt;</span>[Spotlight presentation, 3.5%]<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="271"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2018global-abstract" rel="noreferrer noopener">#xu2018global-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1707.06618" rel="noreferrer noopener">https://arxiv.org/abs/1707.06618</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.youtube.com/watch?v=07NTtzlXE8Y" rel="noreferrer noopener">https://www.youtube.com/watch?v=07NTtzlXE8Y</a>"&gt;</span>Video<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="272"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="273"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2018global-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We present a unified framework to analyze the global convergence of Langevin dynamics based algorithms for nonconvex finite-sum optimization with $n$ component functions.  At the core of our analysis is a direct analysis of the ergodicity of the numerical approximations to Langevin dynamics, which leads to faster convergence rates. Specifically, we show that gradient Langevin dynamics (GLD) and stochastic gradient Langevin dynamics (SGLD)  converge to the $\textit{almost minimizer}$ within $\widetilde O\big(nd/(\lambda\epsilon) \big)$ and $\widetilde O\big(d^7/(\lambda^5\epsilon^5) \big)$ stochastic gradient evaluations respectively, where $d$ is the problem dimension, and $\lambda$ is the spectral gap of the Markov chain generated by GLD. Both results improve upon the best known gradient complexity results \citep{raginsky2017non}. Furthermore, for the first time we prove the global convergence guarantee for variance reduced stochastic gradient Langevin dynamics (SVRG-LD) to the almost minimizer within $\widetilde O\big(\sqrt{n}d^5/(\lambda^4\epsilon^{5/2})\big)$ stochastic gradient evaluations, which outperforms the gradient complexities of GLD and SGLD in a wide regime. Our theoretical analyses shed some light on using Langevin dynamics based algorithms for nonconvex optimization with provable guarantees.</td></tr><tr><td class="line-number" value="274"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="275"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="276"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="277"></td><td class="line-content"></td></tr><tr><td class="line-number" value="278"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2018stochastic-neurips</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Nested Variance Reduction for Nonconvex Optimization<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="279"></td><td class="line-content">Dongrou Zhou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="280"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 31st Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NeurIPS<span class="html-tag">&lt;/b&gt;</span>), Montréal, Canada, 2018.<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publish-type</span>"&gt;</span>[Spotlight presentation, 3.5%]<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="281"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2018stochastic-neurips-abstract" rel="noreferrer noopener">#zhou2018stochastic-neurips-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1806.07811" rel="noreferrer noopener">https://arxiv.org/abs/1806.07811</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.youtube.com/watch?v=xB1bFoYTgXQ&amp;t=55s" rel="noreferrer noopener">https://www.youtube.com/watch?v=xB1bFoYTgXQ&amp;t=55s</a>"&gt;</span>Video<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="282"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="283"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2018stochastic-neurips-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We study finite-sum nonconvex optimization problems, where the objective function is an average of $n$ nonconvex functions. We propose a new stochastic gradient descent algorithm based on nested variance reduction. Compared with conventional stochastic variance reduced gradient (SVRG) algorithm that uses two reference points to construct a semi-stochastic gradient with diminishing variance in each iteration, our algorithm uses $K+1$ nested reference points to build a semi-stochastic gradient to further reduce its variance in each iteration. For smooth nonconvex functions, the proposed algorithm converges to an $\epsilon$-approximate first-order stationary point (i.e., $\|\nabla F(\mathbf{x})\|_2\leq \epsilon$) within $\widetilde O(n\land \epsilon^{-2}+\epsilon^{-3}\land n^{1/2}\epsilon^{-2})$ number of stochastic gradient evaluations. This improves the best known gradient complexity of SVRG $O(n+n^{2/3}\epsilon^{-2})$ and that of SCSG $O(n\land \epsilon^{-2}+\epsilon^{-10/3}\land n^{2/3}\epsilon^{-2})$. For gradient dominated functions, our algorithm also achieves better gradient complexity than the state-of-the-art algorithms. Thorough experimental results on different nonconvex optimization problems back up our theory.</td></tr><tr><td class="line-number" value="284"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="285"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="286"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="287"></td><td class="line-content"></td></tr><tr><td class="line-number" value="288"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Third-order Smoothness Helps: Even Faster Stochastic Optimization Algorithms for Finding Local Minima<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="289"></td><td class="line-content">Yaodong Yu*, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="290"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 31st Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NeurIPS<span class="html-tag">&lt;/b&gt;</span>), Montréal, Canada, 2018.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="291"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#yu2018third-abstract" rel="noreferrer noopener">#yu2018third-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.neurips.cc/paper/2018/hash/fea9c11c4ad9a395a636ed944a28b51a-Abstract.html" rel="noreferrer noopener">https://proceedings.neurips.cc/paper/2018/hash/fea9c11c4ad9a395a636ed944a28b51a-Abstract.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.youtube.com/watch?v=jNH3zqRbPNQ" rel="noreferrer noopener">https://www.youtube.com/watch?v=jNH3zqRbPNQ</a>"&gt;</span>Video<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="292"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="293"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">yu2018third-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose stochastic optimization algorithms that can find local minima faster than existing algorithms for nonconvex optimization problems, by exploiting the third-order smoothness to escape non-degenerate saddle points more efficiently. More specifically, the proposed algorithm only needs $\tilde{O}(\epsilon^{-10/3})$ stochastic gradient evaluations to converge to an approximate local minimum $\mathbf{x}$, which satisfies $\|\nabla f(\mathbf{x})\|_2\leq\epsilon$ and $\lambda_{\min}(\nabla^2 f(\mathbf{x}))\geq -\sqrt{\epsilon}$ in unconstrained stochastic optimization, where $\tilde{O}(\cdot)$ hides logarithm polynomial terms and constants. This improves upon the $\tilde{O}(\epsilon^{-7/2})$ gradient complexity achieved by the state-of-the-art stochastic local minima finding algorithms by a factor of $\tilde{O}(\epsilon^{-1/6})$. Experiments on two nonconvex optimization problems demonstrate the effectiveness of our algorithm and corroborate our theory.</td></tr><tr><td class="line-number" value="294"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="295"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="296"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="297"></td><td class="line-content"></td></tr><tr><td class="line-number" value="298"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Subsampled Stochastic Variance-Reduced Gradient Langevin Dynamics<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="299"></td><td class="line-content">Difan Zou*, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="300"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 34th International Conference on Uncertainty in Artificial Intelligence (<span class="html-tag">&lt;b&gt;</span>UAI<span class="html-tag">&lt;/b&gt;</span>), Monterey, California, USA, 2018. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="301"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zou2018subsampled-abstract" rel="noreferrer noopener">#zou2018subsampled-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://auai.org/uai2018/proceedings/papers/192.pdf" rel="noreferrer noopener">http://auai.org/uai2018/proceedings/papers/192.pdf</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="302"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="303"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zou2018subsampled-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>Stochastic variance-reduced gradient Langevin dynamics (SVRG-LD) was recently proposed to improve the performance of stochastic gradient Langevin dynamics (SGLD) by reducing the variance of the stochastic gradient. In this paper, we propose a variant of SVRG-LD, namely SVRG-LD$^+$, which replaces the full gradient in each epoch with a subsampled one. We provide a nonasymptotic analysis of the convergence of SVRG-LD$^+$ in $2$-Wasserstein distance, and show that SVRG-LD$^+$ enjoys a lower gradient complexity than SVRG-LD, when the sample size is large or the target accuracy requirement is moderate. Our analysis directly implies a sharper convergence rate for SVRG-LD, which improves the existing convergence rate by a factor of $\kappa^{1/6}n^{1/6}$, where $\kappa$ is the condition number of the log-density function and $n$ is the sample size. Experiments on both synthetic and real-world datasets validate our theoretical results.</td></tr><tr><td class="line-number" value="304"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="305"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="306"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="307"></td><td class="line-content"></td></tr><tr><td class="line-number" value="308"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Continuous and Discrete-Time Accelerated Stochastic Mirror Descent for Strongly Convex Functions<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="309"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Tianhao Wang*, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="310"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 35th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Stockholm, Sweden, 2018. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="311"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2018continuous-abstract" rel="noreferrer noopener">#xu2018continuous-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v80/xu18g.html" rel="noreferrer noopener">http://proceedings.mlr.press/v80/xu18g.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="312"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="313"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2018continuous-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span> We provide a second-order stochastic differential equation (SDE), which characterizes the continuous-time dynamics of accelerated stochastic mirror descent (ASMD) for strongly convex functions. This SDE plays a central role in designing new discrete-time ASMD algorithms via numerical discretization and providing neat analyses of their convergence rates based on Lyapunov functions. Our results suggest that the only existing ASMD algorithm, namely, AC-SA proposed in \citet{ghadimi2012optimal} is one instance of its kind, and we can derive new instances of ASMD with fewer tuning parameters.This sheds light on revisiting accelerated stochastic optimization through the lens of SDEs, which can lead to a better understanding as well as new simpler algorithms of acceleration in stochastic optimization. Numerical experiments on both synthetic and real data support our theory. </td></tr><tr><td class="line-number" value="314"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="315"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="316"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="317"></td><td class="line-content"></td></tr><tr><td class="line-number" value="318"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2018stochastic-icml</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Variance-Reduced Cubic Regularized Newton Method<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="319"></td><td class="line-content">Dongruo Zhou, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="320"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 35th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Stockholm, Sweden, 2018. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="321"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zhou2018stochastic-icml-abstract" rel="noreferrer noopener">#zhou2018stochastic-icml-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v80/zhou18d.html" rel="noreferrer noopener">http://proceedings.mlr.press/v80/zhou18d.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] </td></tr><tr><td class="line-number" value="322"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="323"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zhou2018stochastic-icml-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span> We propose a stochastic variance-reduced cubic regularized Newton method (SVRC) for non-convex optimization. At the core of our algorithm is a novel semi-stochastic gradient along with a semi-stochastic Hessian, which are specifically designed for cubic regularization method. We show that our algorithm is guaranteed to converge to an $(\epsilon,\sqrt{\epsilon})$-approximate local minimum within $\widetilde{O}(n^{4/5}/\epsilon^{3/2})$ second-order oracle calls, which outperforms the state-of-the-art cubic regularization algorithms including subsampled cubic regularization. Our work also sheds light on the application of variance reduction technique to high-order non-convex optimization methods. Thorough experiments on various non-convex optimization problems support our theory. </td></tr><tr><td class="line-number" value="324"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="325"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="326"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="327"></td><td class="line-content"></td></tr><tr><td class="line-number" value="328"></td><td class="line-content"><span class="html-tag">&lt;li <span class="html-attribute-name">id</span>="<span class="html-attribute-value">chen2018covariate</span>"&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Stochastic Variance-Reduced Hamilton Monte Carlo Methods<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="329"></td><td class="line-content">Difan Zou*, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="330"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 35th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Stockholm, Sweden, 2018. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="331"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#zou2018stochastic-abstract" rel="noreferrer noopener">#zou2018stochastic-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1802.04791" rel="noreferrer noopener">https://arxiv.org/abs/1802.04791</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="332"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="333"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">zou2018stochastic-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose a fast stochastic Hamilton Monte Carlo (HMC) method, for sampling from a smooth and strongly log-concave distribution. At the core of our proposed method is a variance reduction technique inspired by the recent advance in stochastic optimization. We show that, to achieve $\epsilon$ accuracy in 2-Wasserstein distance, our algorithm achieves $\tilde O\big(n+\kappa^{2}d^{1/2}/\epsilon+\kappa^{4/3}d^{1/3}n^{2/3}/\epsilon^{2/3}\big)$ gradient complexity (i.e., number of component gradient evaluations), which outperforms the state-of-the-art HMC and stochastic gradient HMC methods in a wide regime. We also extend our algorithm for sampling from smooth and general log-concave distributions, and prove the corresponding gradient complexity as well. Experiments on both synthetic and real data demonstrate the superior performance of our algorithm. </td></tr><tr><td class="line-number" value="334"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="335"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span> </td></tr><tr><td class="line-number" value="336"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="337"></td><td class="line-content"></td></tr><tr><td class="line-number" value="338"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="339"></td><td class="line-content">Jinghui Chen, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Lingxiao Wang, Jian Ma, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="340"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 35th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Stockholm, Sweden, 2018.<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publish-type</span>"&gt;</span>[Long talk, 8.6%]<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="341"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#chen2018covariate-abstract" rel="noreferrer noopener">#chen2018covariate-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v80/chen18n.html" rel="noreferrer noopener">http://proceedings.mlr.press/v80/chen18n.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="342"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="343"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">chen2018covariate-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We propose a nonconvex estimator for the covariate adjusted precision matrix estimation problem in the high dimensional regime, under sparsity constraints. To solve this estimator, we propose an alternating gradient descent algorithm with hard thresholding. </td></tr><tr><td class="line-number" value="344"></td><td class="line-content">  Compared with existing methods along this line of research, which lack theoretical guarantees in optimization error and/or statistical error, the proposed algorithm not only is computationally much more efficient with a linear rate of convergence, but also attains the optimal statistical rate up to a logarithmic factor. Thorough experiments on both synthetic and real data support our theory.</td></tr><tr><td class="line-number" value="345"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="346"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="347"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="348"></td><td class="line-content"></td></tr><tr><td class="line-number" value="349"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Accelerated Stochastic Mirror Descent: From Continuous-time Dynamics to Discrete-time Algorithms<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="350"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>*, Tianhao Wang*, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="351"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 21st International Conference on Artificial Intelligence and Statistics (<span class="html-tag">&lt;b&gt;</span>AISTATS<span class="html-tag">&lt;/b&gt;</span>), Playa Blanca, Lanzarote, Canary Islands, 2018. <span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="352"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2018accelerated-abstract" rel="noreferrer noopener">#xu2018accelerated-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/paper/AISTATS18.pdf" rel="noreferrer noopener">paper/AISTATS18.pdf</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] </td></tr><tr><td class="line-number" value="353"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="354"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2018accelerated-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We present a new framework to analyze accelerated stochastic mirror descent through the lens of continuous-time stochastic dynamic systems. </td></tr><tr><td class="line-number" value="355"></td><td class="line-content"> It enables us to design new algorithms, and perform a unified and simple analysis of the convergence rates of these algorithms. More specifically, under this framework, we provide a Lyapunov function based analysis for the continuous-time stochastic dynamics, as well as several new discrete-time algorithms derived from the continuous-time dynamics. We show that for general convex objective functions, the derived discrete-time algorithms attain the optimal convergence rate. Empirical experiments corroborate our theory.</td></tr><tr><td class="line-number" value="356"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="357"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="358"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="359"></td><td class="line-content"><span class="html-comment">&lt;!-- &lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="360"></td><td class="line-content"><span class="html-comment"></span></td></tr><tr><td class="line-number" value="361"></td><td class="line-content"><span class="html-comment">&lt;p&gt;&lt;h3&gt;2017&lt;/h3&gt;	</span></td></tr><tr><td class="line-number" value="362"></td><td class="line-content"><span class="html-comment">&lt;ul&gt; --&gt;</span></td></tr><tr><td class="line-number" value="363"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="364"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Jian Ma, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="365"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 30th Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NIPS<span class="html-tag">&lt;/b&gt;</span>), Long Beach, California, USA, 2017.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="366"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2017speed-abstract" rel="noreferrer noopener">#xu2017speed-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.neurips.cc/paper/2017/hash/ae5e3ce40e0404a45ecacaaf05e5f735-Abstract.html" rel="noreferrer noopener">https://proceedings.neurips.cc/paper/2017/hash/ae5e3ce40e0404a45ecacaaf05e5f735-Abstract.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/paper/poster_lvggm.pdf" rel="noreferrer noopener">paper/poster_lvggm.pdf</a>"&gt;</span>Poster<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://github.com/thughost2/nonconvex-LVGGM" rel="noreferrer noopener">https://github.com/thughost2/nonconvex-LVGGM</a>"&gt;</span>Code<span class="html-tag">&lt;/a&gt;</span>] </td></tr><tr><td class="line-number" value="367"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="368"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2017speed-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>We study the estimation of the latent variable Gaussian graphical model (LVGGM), where the precision matrix is the superposition of a sparse matrix and a low-rank matrix.  In order to speed up the estimation of the sparse plus low-rank components, we propose a sparsity constrained maximum likelihood estimator based on matrix factorization, and an efficient alternating gradient descent algorithm with hard thresholding to solve it. Our algorithm is orders of magnitude faster than the convex relaxation based methods for LVGGM. In addition, we prove that our algorithm is guaranteed to linearly converge to the unknown sparse and low-rank components up to the optimal statistical precision. Experiments on both synthetic and genomic data demonstrate the superiority of our algorithm over the state-of-the-art algorithms and corroborate our theory.  </td></tr><tr><td class="line-number" value="369"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="370"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="371"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="372"></td><td class="line-content"></td></tr><tr><td class="line-number" value="373"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="374"></td><td class="line-content">Aditya Chaudhry, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="375"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 34th International Conference on Machine Learning (<span class="html-tag">&lt;b&gt;</span>ICML<span class="html-tag">&lt;/b&gt;</span>), Sydney, Australia, 2017.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="376"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#aditya2017uncertainty-abstract" rel="noreferrer noopener">#aditya2017uncertainty-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v70/chaudhry17a.html" rel="noreferrer noopener">http://proceedings.mlr.press/v70/chaudhry17a.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="377"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="378"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">aditya2017uncertainty-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>Causal inference among high-dimensional time series data proves an important research problem in many fields. In the classical regime, one often establishes causality among time series via a concept known as “Granger causality.” However, existing approaches for Granger causal inference in high-dimensional data lack the means to characterize the uncertainty associated with Granger causality estimates (e.g. p-values and confidence intervals). We make two contributions in this work. First, we introduce a novel unbiased estimator for assessing Granger causality in the high-dimensional regime. We propose test statistics and confidence intervals for our estimator to allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference. Second, we introduce a novel method for false discovery rate control that achieves higher power in multiple testing than existing techniques and that can cope with dependent test statistics and dependent observations. We corroborate our theoretical results with experiments on both synthetic data and real-world climatological data.</td></tr><tr><td class="line-number" value="379"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="380"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span> </td></tr><tr><td class="line-number" value="381"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="382"></td><td class="line-content"></td></tr><tr><td class="line-number" value="383"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Efficient Algorithm for Sparse Tensor-variate Gaussian Graphical Models via Gradient Descent<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="384"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Tingting Zhang, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="385"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 20th International Conference on Artificial Intelligence and Statistics (<span class="html-tag">&lt;b&gt;</span>AISTATS<span class="html-tag">&lt;/b&gt;</span>), Fort Lauderdale, Florida, USA, 2017.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="386"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2017efficient-abstract" rel="noreferrer noopener">#xu2017efficient-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://proceedings.mlr.press/v54/xu17b.html" rel="noreferrer noopener">http://proceedings.mlr.press/v54/xu17b.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] </td></tr><tr><td class="line-number" value="387"></td><td class="line-content"><span class="html-tag">&lt;div <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2017efficient-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span></td></tr><tr><td class="line-number" value="388"></td><td class="line-content">	<span class="html-tag">&lt;p&gt;</span>We study the sparse tensor-variate Gaussian graphical model (STGGM), where each way of the tensor follows a multivariate normal distribution whose precision matrix has sparse structures. To estimate the precision matrices, we propose a sparsity constrained maximum likelihood estimator. However, due to the complex structure of the tensor-variate GGMs, the likelihood based estimator is non-convex, which poses great challenges for both computation and theoretical analysis. In order to address these challenges, we propose an efficient alternating gradient descent algorithm to solve this estimator and prove that, under certain conditions on the initial estimator, our algorithm is guaranteed to linearly converge to the unknown precision matrices up to the optimal statistical error. Experiments on both synthetic data and real world brain imaging data corroborate our theory.</td></tr><tr><td class="line-number" value="389"></td><td class="line-content">	<span class="html-tag">&lt;/p&gt;</span>	</td></tr><tr><td class="line-number" value="390"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="391"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="392"></td><td class="line-content"><span class="html-comment">&lt;!-- &lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="393"></td><td class="line-content"><span class="html-comment"></span></td></tr><tr><td class="line-number" value="394"></td><td class="line-content"><span class="html-comment">&lt;p&gt;&lt;h3&gt;2016&lt;/h3&gt;	</span></td></tr><tr><td class="line-number" value="395"></td><td class="line-content"><span class="html-comment">&lt;ul&gt; --&gt;</span></td></tr><tr><td class="line-number" value="396"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Semiparametric Differential Graph Models<span class="html-tag">&lt;/span&gt;</span> <span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="397"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="398"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 29th Conference on Advances in Neural Information Processing Systems (<span class="html-tag">&lt;b&gt;</span>NIPS<span class="html-tag">&lt;/b&gt;</span>), Barcelona, Spain, 2016.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="399"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#xu2016semiparametric-abstract" rel="noreferrer noopener">#xu2016semiparametric-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://proceedings.neurips.cc/paper/2016/hash/f76a89f0cb91bc419542ce9fa43902dc-Abstract.html" rel="noreferrer noopener">https://proceedings.neurips.cc/paper/2016/hash/f76a89f0cb91bc419542ce9fa43902dc-Abstract.html</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://youtu.be/zraGh6vWXt0" rel="noreferrer noopener">https://youtu.be/zraGh6vWXt0</a>"&gt;</span>Video<span class="html-tag">&lt;/a&gt;</span>]</td></tr><tr><td class="line-number" value="400"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="401"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">xu2016semiparametric-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>In many cases of network analysis, it is more attractive to study how a network varies under different conditions than an individual static network. We propose a novel graphical model, namely the Latent Differential Graph Model, where the networks under two different conditions are represented by two semiparametric elliptical distributions respectively, and the variation of these two networks (i.e., differential graph) is characterized by the difference between their latent precision matrices. We propose an estimator for the differential graph based on quasi-likelihood maximization with nonconvex regularization. We show that our estimator attains a faster statistical rate in parameter estimation than the state-of-the-art methods, and enjoys the oracle property under mild conditions. Thorough experiments on both synthetic and real-world data support our theory.</td></tr><tr><td class="line-number" value="402"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="403"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span>  	</td></tr><tr><td class="line-number" value="404"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="405"></td><td class="line-content"></td></tr><tr><td class="line-number" value="406"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">paper-title</span>"&gt;</span>Forward Backward Greedy Algorithms for Multi-Task Learning with Faster Rates<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="407"></td><td class="line-content">Lu Tian, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Quanquan Gu<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="408"></td><td class="line-content"><span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>In Proc. of the 32nd International Conference on Uncertainty in Artificial Intelligence (<span class="html-tag">&lt;b&gt;</span>UAI<span class="html-tag">&lt;/b&gt;</span>), New York / New Jersey, USA, 2016.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="409"></td><td class="line-content">[<span class="html-tag">&lt;a <span class="html-attribute-name">data-toggle</span>="<span class="html-attribute-value">collapse</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://panxu-ai.github.io/publication#tian2016forward-abstract" rel="noreferrer noopener">#tian2016forward-abstract</a>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">my_details</span>"&gt;</span>Summary<span class="html-tag">&lt;/a&gt;</span>] [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="http://auai.org/uai2016/proceedings/papers/135.pdf" rel="noreferrer noopener">http://auai.org/uai2016/proceedings/papers/135.pdf</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>] </td></tr><tr><td class="line-number" value="410"></td><td class="line-content"><span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="411"></td><td class="line-content">  <span class="html-tag">&lt;p <span class="html-attribute-name">id</span>="<span class="html-attribute-value">tian2016forward-abstract</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">abstract collapse</span>"&gt;</span>In this paper, we develop a multi-task learning algorithm with faster convergence rates. In particular, we propose a general estimator for multitask learning with row sparsity constraints on the parameter matrix. The proposed estimator is a nonconvex optimization problem. To solve it, we develop a forward backward greedy algorithm with provable guarantees. More specifically, we prove that the output of the greedy algorithm attains a sharper estimation error bound than state-of-the-art multi-task learning methods. Moreover, our estimator enjoys model selection consistency under mild conditions. Thorough experiments on both synthetic and real-world data demonstrate the effectiveness of our method and back up our theory.</td></tr><tr><td class="line-number" value="412"></td><td class="line-content">  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="413"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="414"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="415"></td><td class="line-content"><span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="416"></td><td class="line-content"></td></tr><tr><td class="line-number" value="417"></td><td class="line-content"><span class="html-tag">&lt;p&gt;</span><span class="html-tag">&lt;h5&gt;</span>PREPRINTS<span class="html-tag">&lt;/h5&gt;</span><span class="html-tag">&lt;/p&gt;</span> </td></tr><tr><td class="line-number" value="418"></td><td class="line-content"><span class="html-tag">&lt;ul&gt;</span>	</td></tr><tr><td class="line-number" value="419"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span>Finite-Time Regret of Thompson Sampling Algorithms for Exponential Family Multi-Armed Bandits [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/2206.03520" rel="noreferrer noopener">https://arxiv.org/abs/2206.03520</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="420"></td><td class="line-content">Tianyuan Jin, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Xiaokui Xiao, Anima Anandkumar, <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>arXiv:2206.03520.<span class="html-tag">&lt;/span&gt;</span>	</td></tr><tr><td class="line-number" value="421"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="422"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span>COVID-19 Reopening Strategies at the County Level in the Face of Uncertainty: Multiple Models for Outbreak Decision Support [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.medrxiv.org/content/10.1101/2020.11.03.20225409v1" rel="noreferrer noopener">https://www.medrxiv.org/content/10.1101/2020.11.03.20225409v1</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="423"></td><td class="line-content">Katriona Shea, ..., <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, ..., Michael C. Runge, <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>medRxiv: 2020.11.03.20225409.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="424"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>		</td></tr><tr><td class="line-number" value="425"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span>Ensemble Forecasts of Coronavirus Disease 2019 (COVID-19) in the U.S. [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.medrxiv.org/content/10.1101/2020.08.19.20177493v1" rel="noreferrer noopener">https://www.medrxiv.org/content/10.1101/2020.08.19.20177493v1</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="426"></td><td class="line-content">COVID-19 Forecast Hub Consortium, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>medRxiv: 2020.08.19.20177493.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="427"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>	</td></tr><tr><td class="line-number" value="428"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span>Epidemic Model Guided Machine Learning for COVID-19 Forecasts in the United States [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.medrxiv.org/content/10.1101/2020.05.24.20111989v1" rel="noreferrer noopener">https://www.medrxiv.org/content/10.1101/2020.05.24.20111989v1</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="429"></td><td class="line-content">Difan Zou, Lingxiao Wang, <span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Jinghui Chen, Weitong Zhang, Quanquan Gu, <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>medRxiv: 2020.05.24.2011198.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="430"></td><td class="line-content">This work has been presented at the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://mlpcp21.github.io/index.html" rel="noreferrer noopener">https://mlpcp21.github.io/index.html</a>"&gt;</span>ICLR 2021 Machine Learning for Preventing and Combating Pandemics Workshop<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span> 	</td></tr><tr><td class="line-number" value="431"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span>				</td></tr><tr><td class="line-number" value="432"></td><td class="line-content"><span class="html-tag">&lt;li&gt;</span>Communication-efficient Distributed Estimation and Inference for Transelliptical Graphical Models [<span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/1612.09297" rel="noreferrer noopener">https://arxiv.org/abs/1612.09297</a>"&gt;</span>Paper<span class="html-tag">&lt;/a&gt;</span>]<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="433"></td><td class="line-content"><span class="html-tag">&lt;b&gt;</span>Pan Xu<span class="html-tag">&lt;/b&gt;</span>, Lu Tian, Quanquan Gu, <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span>arXiv:1612.09297.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="434"></td><td class="line-content">This work has been presented at the <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">publisher</span>"&gt;</span><span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://www.enar.org/meetings/spring2016/" rel="noreferrer noopener">https://www.enar.org/meetings/spring2016/</a>"&gt;</span>ENAR 2016 Spring Meeting<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span>.<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="435"></td><td class="line-content"><span class="html-tag">&lt;/li&gt;</span><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="436"></td><td class="line-content"><span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="437"></td><td class="line-content"></td></tr><tr><td class="line-number" value="438"></td><td class="line-content"><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="439"></td><td class="line-content"><span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="440"></td><td class="line-content"><span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">display:none;width:300px;</span>"&gt;</span><span class="html-tag">&lt;script <span class="html-attribute-name">type</span>="<span class="html-attribute-value">text/javascript</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://ri.revolvermaps.com/0/0/7.js?i=8y358xon9fx&amp;m=7&amp;s=320&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" rel="noreferrer noopener">//ri.revolvermaps.com/0/0/7.js?i=8y358xon9fx&amp;amp;m=7&amp;amp;s=320&amp;amp;c=e63100&amp;amp;cr1=ffffff&amp;amp;f=arial&amp;amp;l=0&amp;amp;bv=90&amp;amp;lx=-420&amp;amp;ly=420&amp;amp;hi=20&amp;amp;he=7&amp;amp;hc=a8ddff&amp;amp;rs=80</a>" <span class="html-attribute-name">async</span>="<span class="html-attribute-value">async</span>"&gt;</span><span class="html-tag">&lt;/script&gt;</span> <span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="441"></td><td class="line-content"></td></tr><tr><td class="line-number" value="442"></td><td class="line-content"><span class="html-tag">&lt;/html&gt;</span></td></tr><tr><td class="line-number" value="443"></td><td class="line-content"></td></tr><tr><td class="line-number" value="444"></td><td class="line-content"><span class="html-end-of-file"></span></td></tr></tbody></table></body></html>